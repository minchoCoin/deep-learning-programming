{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "w8FxqpVNUBVZ",
   "metadata": {
    "id": "w8FxqpVNUBVZ"
   },
   "source": [
    "#LAB 3: Faster RCNN\n",
    "\n",
    "<h4><div style=\"text-align: right\"> Due date: 15:00 Nov 11, 2024.  </div> <br>\n",
    "<div style=\"text-align: right\"> Please upload your file and final-report at PLATO before the class in the form of [ID_Name_Lab1.ipynb]. </div></h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nfqy0tJJUBVc",
   "metadata": {
    "id": "nfqy0tJJUBVc"
   },
   "source": [
    "### *Instructions:*\n",
    "- Write a program implementing a particular algorithm to solve a given problem.   \n",
    "- <span style=\"color:red\">**Report and discuss your results. Analyze the algorithm, theoretically and empirically.**</span>\n",
    "- You must write their own answers and codes (<span style=\"color:red\">**if not you will get a F grade**</span>).\n",
    "- Download the dataset using the following code line;\n",
    "wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000266/data/data.tar.gz\n",
    "\n",
    "- For more information, please refer (https://stages.ai/competitions/325/data/overview)\n",
    "> Copyright: CC BY 2.0\n",
    "\n",
    "### dataset\n",
    "    ├── train.json\n",
    "    ├── test.json\n",
    "    ├── train\n",
    "    └── test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M9d5XT4NlBn4",
   "metadata": {
    "id": "M9d5XT4NlBn4"
   },
   "source": [
    "<h2><span style=\"color:blue\">[201924451] [김태훈]</span> </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06b9612-2ca2-44d2-91cd-e98c7e48b101",
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -zxf data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05253a3a-eea0-456a-8223-313b2f7a4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # Arrange GPU devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" # Set the GPU 2 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hV9rydzjlDJy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hV9rydzjlDJy",
    "outputId": "aee18b27-3578-4d56-aa2f-499a8b245d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This code is written at 2024-11-08 09:17:38.498498\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"This code is written at \" + str(datetime.datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xsgTBr3BqE8z",
   "metadata": {
    "id": "xsgTBr3BqE8z"
   },
   "source": [
    "# Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22845921-6d88-4aeb-a113-96894f372537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations==1.3.1 in /home/team112/.local/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/team112/.local/lib/python3.8/site-packages (from albumentations==1.3.1) (4.10.0.84)\n",
      "Requirement already satisfied: PyYAML in /usr/lib/python3/dist-packages (from albumentations==1.3.1) (5.3.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/team112/.local/lib/python3.8/site-packages (from albumentations==1.3.1) (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from albumentations==1.3.1) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/team112/.local/lib/python3.8/site-packages (from albumentations==1.3.1) (1.10.1)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /home/team112/.local/lib/python3.8/site-packages (from albumentations==1.3.1) (0.0.4)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/team112/.local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.35.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/team112/.local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (1.4.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (10.3.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/team112/.local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2023.7.10)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (3.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/team112/.local/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (0.4)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.8/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (24.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/team112/.local/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (4.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/team112/.local/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/team112/.local/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "JEa9vTBhUBVd",
   "metadata": {
    "id": "JEa9vTBhUBVd"
   },
   "outputs": [],
   "source": [
    "# 권장 환경: python==3.7.13, pytorch==1.13.1, torchvision==0.14.1, albumentations==1.3.1, torchnet==0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce329765",
   "metadata": {
    "id": "ce329765"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54d76dda",
   "metadata": {
    "id": "54d76dda"
   },
   "outputs": [],
   "source": [
    "# !pip install visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c142ed1a",
   "metadata": {
    "id": "c142ed1a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import six\n",
    "from collections import namedtuple\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models import vgg16\n",
    "from torchvision.ops import RoIPool\n",
    "from torchvision.ops import nms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils import data as data_\n",
    "\n",
    "from torchnet.meter import ConfusionMeter, AverageValueMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2wb--qP79Xx2",
   "metadata": {
    "id": "2wb--qP79Xx2"
   },
   "source": [
    "# Util Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebae2a20",
   "metadata": {
    "id": "ebae2a20"
   },
   "outputs": [],
   "source": [
    "def loc2bbox(src_bbox, loc):\n",
    "    \"\"\"\n",
    "    Decodes bouding boxes from bounding box offsets and scales.\n",
    "\n",
    "    Args:\n",
    "        src_bbox: A coordinates of bounding boxes.\n",
    "            These coordinates are (p_ymin, p_xmin, p_ymax, p_xmax).\n",
    "        loc: An array with offsets and scales.\n",
    "            The shapes of 'src_bbox' and 'loc' should be same.\n",
    "            This contains values: (t_y, t_x, t_h, t_w).\n",
    "    Returns: Decoded bounding box coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    if src_bbox.shape[0] == 0:\n",
    "        return np.zeros((0, 4), dtype=loc.dtype)\n",
    "\n",
    "    src_bbox = src_bbox.astype(src_bbox.dtype, copy=False)\n",
    "    src_height = src_bbox[:, 2] - src_bbox[:, 0]\n",
    "    src_width = src_bbox[:, 3] - src_bbox[:, 1]\n",
    "    src_ctr_y = src_bbox[:, 0] + 0.5 * src_height\n",
    "    src_ctr_x = src_bbox[:, 1] + 0.5 * src_width\n",
    "\n",
    "    dy = loc[:, 0::4]\n",
    "    dx = loc[:, 1::4]\n",
    "    dh = loc[:, 2::4]\n",
    "    dw = loc[:, 3::4]\n",
    "\n",
    "    ctr_y = dy * src_height[:, np.newaxis] + src_ctr_y[:, np.newaxis]\n",
    "    ctr_x = dx * src_width[:, np.newaxis] + src_ctr_x[:, np.newaxis]\n",
    "    h = np.exp(dh) * src_height[:, np.newaxis]\n",
    "    w = np.exp(dw) * src_width[:, np.newaxis]\n",
    "\n",
    "    dst_bbox = np.zeros(loc.shape, dtype=loc.dtype)\n",
    "    dst_bbox[:, 0::4] = ctr_y - 0.5 * h\n",
    "    dst_bbox[:, 1::4] = ctr_x - 0.5 * w\n",
    "    dst_bbox[:, 2::4] = ctr_y + 0.5 * h\n",
    "    dst_bbox[:, 3::4] = ctr_x + 0.5 * w\n",
    "\n",
    "    return dst_bbox\n",
    "\n",
    "\n",
    "def bbox2loc(src_bbox, dst_bbox):\n",
    "    \"\"\"\n",
    "    Encodes the source and the destination bouding boxes to \"loc\".\n",
    "\n",
    "    The offsets and scales t_y, t_x, t_h, t_w can be computed by the following formulas\n",
    "    t_y = (g_y - p_y) / p_h\n",
    "    t_x = (g_x - p_x) / p_w\n",
    "    t_h = log(g_h / p_h)\n",
    "    t_w = log(g_w / p_W)\n",
    "\n",
    "    Args:\n",
    "        src_bbox: These coordinates are (p_ymin, p_xmin, p_ymax, p_xmax).\n",
    "        dst_bbox: These coordinates are (g_ymin, g_xmin, g_ymax, g_xmax).\n",
    "\n",
    "    Returns:\n",
    "        Bounding box offsets and scales from src_bbox to dst_bbox.\n",
    "        The second axis contains four values (t_y, t_x, t_h, t_w).\n",
    "    \"\"\"\n",
    "\n",
    "    # x_min, y_min, x_max, y_max\n",
    "    height = src_bbox[:, 2] - src_bbox[:, 0]\n",
    "    width = src_bbox[:, 3] - src_bbox[:, 1]\n",
    "    ctr_y = src_bbox[:, 0] + 0.5 * height\n",
    "    ctr_x = src_bbox[:, 1] + 0.5 * width\n",
    "\n",
    "    # x_min, y_min, x_max, y_max\n",
    "    base_height = dst_bbox[:, 2] - dst_bbox[:, 0]\n",
    "    base_width = dst_bbox[:, 3] - dst_bbox[:, 1]\n",
    "    base_ctr_y = dst_bbox[:, 0] + 0.5 * base_height\n",
    "    base_ctr_x = dst_bbox[:, 1] + 0.5 * base_width\n",
    "\n",
    "    eps = np.finfo(height.dtype).eps\n",
    "    height = np.maximum(height, eps)\n",
    "    width = np.maximum(width, eps)\n",
    "\n",
    "    dy = (base_ctr_y - ctr_y) / height\n",
    "    dx = (base_ctr_x - ctr_x) / width\n",
    "    dh = np.log(base_height / height)\n",
    "    dw = np.log(base_width / width)\n",
    "\n",
    "    loc = np.vstack((dy, dx, dh, dw)).transpose()\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1DTpLq7_9Qr2",
   "metadata": {
    "id": "1DTpLq7_9Qr2"
   },
   "outputs": [],
   "source": [
    "def normal_init(m, mean, stddev, truncated=False):\n",
    "    \"\"\"\n",
    "    weight initialization\n",
    "    \"\"\"\n",
    "    if truncated:\n",
    "        m.weight.data.normal_().fmod_(2).mul_(stddev).add_(mean)\n",
    "    else:\n",
    "        m.weight.data.normal_(mean, stddev)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def get_inside_index(anchor, H, W):\n",
    "    # Calc indicies of anchors which are located completely inside of the image\n",
    "    # whose size is speficied.\n",
    "    index_inside = np.where(\n",
    "        (anchor[:, 0] >= 0) &\n",
    "        (anchor[:, 1] >= 0) &\n",
    "        (anchor[:, 2] <= H) &\n",
    "        (anchor[:, 3] <= W)\n",
    "    )[0]\n",
    "    return index_inside\n",
    "\n",
    "\n",
    "def unmap(data, count, index, fill=0):\n",
    "    # Unmap a subset of item (data) back to the original set of items (of size count)\n",
    "    if len(data.shape) == 1:\n",
    "        ret = np.empty((count,), dtype=data.dtype)\n",
    "        ret.fill(fill)\n",
    "        ret[index] = data\n",
    "    else:\n",
    "        ret = np.empty((count,) + data.shape[1:], dtype=data.dtype)\n",
    "        ret.fill(fill)\n",
    "        ret[index, :] = data\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e49054b",
   "metadata": {
    "id": "7e49054b"
   },
   "outputs": [],
   "source": [
    "def tonumpy(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return data.detach().cpu().numpy()\n",
    "\n",
    "def totensor(data, cuda = True):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        tensor = torch.from_numpy(data)\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        tensor = data.detach()\n",
    "    if cuda:\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def scalar(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data.reshape(1)[0]\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        return data.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PJhVDlP3qA7h",
   "metadata": {
    "id": "PJhVDlP3qA7h"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecf14d",
   "metadata": {
    "id": "e0ecf14d"
   },
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "166d1663",
   "metadata": {
    "id": "166d1663"
   },
   "outputs": [],
   "source": [
    "epochs=14\n",
    "learning_rate = 1e-3\n",
    "lr_decay = 0.1\n",
    "weight_decay = 0.0005\n",
    "# use dropout in RoIHead\n",
    "use_drop = False\n",
    "\n",
    "rpn_sigma = 3.     # sigma for l1_smooth_loss (RPN loss)\n",
    "roi_sigma = 1.     # sigma for l1_smooth_loss (ROI loss)\n",
    "\n",
    "# 데이터 경로\n",
    "data_dir = './dataset'\n",
    "# train시 checkpoint 경로\n",
    "train_load_path =None\n",
    "# inference시 체크포인트 경로\n",
    "inf_load_path = './checkpoints/faster_rcnn_scratch_checkpoints.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fb9a7d",
   "metadata": {
    "id": "49fb9a7d"
   },
   "source": [
    "### Dataset loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a093db22",
   "metadata": {
    "id": "a093db22"
   },
   "source": [
    "#### 1. TrainCustom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e08cf31",
   "metadata": {
    "id": "6e08cf31"
   },
   "outputs": [],
   "source": [
    "# TrainDataset\n",
    "class TrainCustom(Dataset):\n",
    "    def __init__(self, annotation, data_dir, transforms = False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotation: annotation 파일 위치\n",
    "            data_dir: data가 존재하는 폴더 경로\n",
    "            transforms : transform 여부\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        # 이미지 아이디 가져오기\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        # 이미지 정보 가져오기\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # 이미지 로드\n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "\n",
    "        # 어노테이션 파일 로드\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_info['id'])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # 박스 가져오기\n",
    "        boxes = np.array([x['bbox'] for x in anns])\n",
    "\n",
    "        # boxes (x_min, y_min, x_max, y_max) 꼴로 변환\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "\n",
    "        # 레이블 가져오기\n",
    "        labels = np.array([x['category_id'] for x in anns])\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "\n",
    "        # transform 함수 정의\n",
    "        if self.transforms :\n",
    "            scale = 1.0  # resize scale\n",
    "            H, W, _ = image.shape\n",
    "            resize_H = int(scale * H)\n",
    "            resize_W = int(scale * W)\n",
    "            transforms = get_train_transform(resize_H, resize_W)\n",
    "        else :\n",
    "            scale = 1.0\n",
    "            transforms = no_transform()\n",
    "\n",
    "        # transform\n",
    "        sample = {\n",
    "            'image': image,\n",
    "            'bboxes': boxes,\n",
    "            'labels': labels\n",
    "        }\n",
    "        sample = transforms(**sample)\n",
    "        image = sample['image']\n",
    "        bboxes = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "        boxes = torch.tensor(sample['bboxes'], dtype=torch.float32)\n",
    "\n",
    "        # bboxes (x_min, y_min, x_max, y_max) -> boxes (y_min, x_min, y_max, x_max)\n",
    "        boxes[:, 0] = bboxes[:, 1]\n",
    "        boxes[:, 1] = bboxes[:, 0]\n",
    "        boxes[:, 2] = bboxes[:, 3]\n",
    "        boxes[:, 3] = bboxes[:, 2]\n",
    "\n",
    "        return image, boxes, labels, scale\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856a66d5",
   "metadata": {
    "id": "856a66d5"
   },
   "outputs": [],
   "source": [
    "# Test Dataset\n",
    "class TestCustom(Dataset):\n",
    "    def __init__(self, annotation, data_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            annotation: annotation 파일 위치\n",
    "            data_dir: data가 존재하는 폴더 경로\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        # coco annotation 불러오기 (coco API)\n",
    "        self.coco = COCO(annotation)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "\n",
    "        # 이미지 아이디 가져오기\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "\n",
    "        # 이미지 정보 가져오기\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # 이미지 로드\n",
    "        image = cv2.imread(os.path.join(self.data_dir, image_info['file_name']))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        image /= 255.0\n",
    "        image = torch.tensor(image, dtype = torch.float).permute(2,0,1)\n",
    "\n",
    "        return image, image.shape[1:]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc847ee7",
   "metadata": {
    "id": "bc847ee7"
   },
   "source": [
    "#### 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d2af672",
   "metadata": {
    "id": "6d2af672"
   },
   "outputs": [],
   "source": [
    "# Train dataset transform\n",
    "def get_train_transform(h, w):\n",
    "    return A.Compose([\n",
    "        A.Resize(height = h, width = w),\n",
    "        A.Flip(p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5), # add\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.5), # add\n",
    "        ToTensorV2(p=1.0)\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
    "\n",
    "# No transform\n",
    "def no_transform():\n",
    "    return A.Compose([\n",
    "        ToTensorV2(p=1.0) # format for pytorch tensor\n",
    "    ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a02619",
   "metadata": {
    "id": "e8a02619"
   },
   "source": [
    "### RPN (Region Proposal Network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43368909",
   "metadata": {
    "id": "43368909"
   },
   "source": [
    "#### 1. Anchor box generator\n",
    "\n",
    "👉 mission1. anchor box 좌표값 생성\n",
    "1. 중점 만들기 (base_size의 절반)\n",
    "\n",
    "\n",
    "2. 하나의 중점당 ratio와 anchor scales에 따라 9개의 anchor box의 좌표값 만들기\\\n",
    "    anchor box의 좌표값 : (y_min, x_min, y_max, x_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2155d0ec",
   "metadata": {
    "id": "2155d0ec"
   },
   "outputs": [],
   "source": [
    "def generate_anchor_base(base_size=16, ratios=[0.5, 1, 2], anchor_scales=[8, 16, 32]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ratios: 비율\n",
    "        anchor_scales: 스케일\n",
    "    Returns: basic anchor boxes, shape=(R, 4)\n",
    "        R: len(ratio) * len(anchor_scales) = anchor 개수 = 9\n",
    "        4: anchor box 좌표 값\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    ### ANSWER HERE ###\n",
    "    # 구현해야 할 변수 : px, py\n",
    "      # px\n",
    "      # py\n",
    "    py = base_size / 2.0\n",
    "    px = base_size / 2.0\n",
    "\n",
    "    anchor_base = np.zeros((len(ratios) * len(anchor_scales), 4), dtype=np.float32) # anchor_box\n",
    "\n",
    "    for i in six.moves.range(len(ratios)):\n",
    "        for j in six.moves.range(len(anchor_scales)):\n",
    "            h = base_size * anchor_scales[j] * np.sqrt(ratios[i])\n",
    "            w = base_size * anchor_scales[j] * np.sqrt(1. / ratios[i])\n",
    "\n",
    "            index = i * len(anchor_scales) + j\n",
    "            # offset of anchor box\n",
    "\n",
    "            ### YOUR CODE HERE\n",
    "            ### ANSWER HERE ###\n",
    "            # 구현해야 할 변수 : anchor_base\n",
    "            # anchor_base[index, 0]\n",
    "            # anchor_base[index, 1]\n",
    "            # anchor_base[index, 2]\n",
    "            # anchor_base[index, 3]\n",
    "            anchor_base[index, 0] = py - h / 2.0\n",
    "            anchor_base[index, 1] = px - w / 2.0\n",
    "            anchor_base[index, 2] = py + h / 2.0\n",
    "            anchor_base[index, 3] = px + w / 2.0\n",
    "\n",
    "    return anchor_base # (9,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74ef20d",
   "metadata": {
    "id": "e74ef20d"
   },
   "source": [
    "#### 2. ProposalCreator\n",
    "RPN에서 구한 rpn_loc와 anchor을 통해서 Region of Interest(RoI)를 생성\\\n",
    "RoI 개수 줄이기 위해서 미리 정해둔 크기(min_size)에 맞는 roi들 중 NMS를 통해 최종 RoI 반환 (train 시 2000개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af7541e",
   "metadata": {
    "id": "4af7541e"
   },
   "outputs": [],
   "source": [
    "class ProposalCreator:\n",
    "    def __init__(self, parent_model,\n",
    "                 nms_thresh=0.7, # nms threshold\n",
    "                 n_train_pre_nms=12000, # train시 nms 전 roi 개수\n",
    "                 n_train_post_nms=2000, # train시 nms 후 roi 개수\n",
    "                 n_test_pre_nms=6000,   # test시 nms 전 roi 개수\n",
    "                 n_test_post_nms=300,   # test시 nms 후 roi 개수\n",
    "                 min_size=16\n",
    "                 ):\n",
    "        self.parent_model = parent_model\n",
    "        self.nms_thresh = nms_thresh\n",
    "        self.n_train_pre_nms = n_train_pre_nms\n",
    "        self.n_train_post_nms = n_train_post_nms\n",
    "        self.n_test_pre_nms = n_test_pre_nms\n",
    "        self.n_test_post_nms = n_test_post_nms\n",
    "        self.min_size = min_size\n",
    "\n",
    "    def __call__(self, loc, score, anchor, img_size, scale=1.):\n",
    "        if self.parent_model.training: # train중일 때\n",
    "            n_pre_nms = self.n_train_pre_nms\n",
    "            n_post_nms = self.n_train_post_nms\n",
    "        else: # test중일 때\n",
    "            n_pre_nms = self.n_test_pre_nms\n",
    "            n_post_nms = self.n_test_post_nms\n",
    "\n",
    "        # anchor의 좌표값과 predicted bounding bounding box offset(y,x,h,w)를 통해\n",
    "        # bounding box 좌표값(y_min, x_min, y_max, x_max) 생성\n",
    "        roi = loc2bbox(anchor, loc)\n",
    "\n",
    "        # Clip predicted boxes to image.\n",
    "        roi[:, slice(0, 4, 2)] = np.clip(roi[:, slice(0, 4, 2)], 0, img_size[0])\n",
    "        roi[:, slice(1, 4, 2)] = np.clip(roi[:, slice(1, 4, 2)], 0, img_size[1])\n",
    "\n",
    "        # min_size 보다 작은 box들은 제거\n",
    "        min_size = self.min_size * scale\n",
    "        hs = roi[:, 2] - roi[:, 0]\n",
    "        ws = roi[:, 3] - roi[:, 1]\n",
    "        keep = np.where((hs >= min_size) & (ws >= min_size))[0]\n",
    "        roi = roi[keep, :]\n",
    "        score = score[keep]\n",
    "\n",
    "        # Sort all (proposal, score) pairs by score from highest to lowest.\n",
    "        # Take top pre_nms_topN\n",
    "        order = score.ravel().argsort()[::-1]\n",
    "        if n_pre_nms > 0:\n",
    "            order = order[:n_pre_nms]\n",
    "        roi = roi[order, :]\n",
    "        score = score[order]\n",
    "\n",
    "        # nms 적용\n",
    "        keep = nms(\n",
    "            torch.from_numpy(roi).cuda(),\n",
    "            torch.from_numpy(score).cuda(),\n",
    "            self.nms_thresh)\n",
    "        if n_post_nms > 0:\n",
    "            keep = keep[:n_post_nms]\n",
    "        roi = roi[keep.cpu().numpy()]\n",
    "\n",
    "        return roi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a991ada",
   "metadata": {
    "id": "7a991ada"
   },
   "source": [
    "#### 3. region proposal network\n",
    "\n",
    "VGG16 통과한 feature map으로부터 region proposal들 생성\n",
    "\n",
    "👉 mission2. Region Proposal Network\n",
    " **tensor shape은 모두 1024x1024 이미지 기준입니다.**\n",
    "1. backbone에서 나온 feature map에 3x3 conv 연산을 적용하여 중간 feature map 생성 \\\n",
    "    input: x (torch.Size([1, 512, 64, 64]))\\\n",
    "    output: middle (torch.Size([1, 512, 64, 64]))\n",
    "    \n",
    "    \n",
    "2. middle(중간 feature map)에 1x1 conv 연산을 적용하여 9x4(anchor box의 수 x bounding box 좌표값)개의 channel을 가지는 feature map 생성\\\n",
    "    input: middle (torch.Size([1, 512, 64, 64]))\\\n",
    "    output: rpn_locs (torch.Size([1, 36, 64, 64]))\n",
    "    \n",
    "    \n",
    "3. middle(중간 feature map)에 1x1 conv 연산을 적용하여 9x2(anchor box의 수 x object 여부)개의 channel을 가지는 feature map 생성\\\n",
    "    input: middle (torch.Size([1, 512, 64, 64]))\\\n",
    "    output: rpn_locs (torch.Size([1, 18, 64, 64]))\n",
    "    \n",
    "    \n",
    "4. Proposal Creator 함수를 사용하여 roi 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb749c00",
   "metadata": {
    "id": "cb749c00"
   },
   "outputs": [],
   "source": [
    "class RegionProposalNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=512, mid_channels=512, ratios=[0.5, 1, 2],\n",
    "                 anchor_scales=[8, 16, 32], feat_stride=16, proposal_creator_params=dict(),):\n",
    "\n",
    "        super(RegionProposalNetwork, self).__init__()\n",
    "\n",
    "        self.anchor_base = generate_anchor_base(anchor_scales=anchor_scales, ratios=ratios) # 9개의 anchorbox 생성\n",
    "        self.feat_stride = feat_stride\n",
    "        self.proposal_layer = ProposalCreator(self, **proposal_creator_params) # proposal_creator_params : 해당 네트워크가 training인지 testing인지 알려준다.\n",
    "        n_anchor = self.anchor_base.shape[0] # anchor 개수\n",
    "        self.conv1 = nn.Conv2d(in_channels, mid_channels, 3, 1, 1)\n",
    "        self.score = nn.Conv2d(mid_channels, n_anchor * 2, 1, 1, 0)  # 9*2\n",
    "        self.loc = nn.Conv2d(mid_channels, n_anchor * 4, 1, 1, 0)   # 9*4\n",
    "        normal_init(self.conv1, 0, 0.01) # weight initalizer\n",
    "        normal_init(self.score, 0, 0.01) # weight initalizer\n",
    "        normal_init(self.loc, 0, 0.01)   # weight initalizer\n",
    "\n",
    "    def forward(self, x, img_size, scale=1.):\n",
    "        # x(feature map)\n",
    "        n, _, hh, ww = x.shape\n",
    "\n",
    "        # 전체 (h*w*9)개 anchor의 좌표값 # anchor_base:(9, 4)\n",
    "        anchor = _enumerate_shifted_anchor(np.array(self.anchor_base), self.feat_stride, hh, ww)\n",
    "        n_anchor = anchor.shape[0] // (hh * ww) # anchor 개수\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        ### ANSWER HERE ###\n",
    "        middle = F.relu(self.conv1(x))\n",
    "\n",
    "        # predicted bounding box offset\n",
    "        ### YOUR CODE HERE\n",
    "        ### ANSWER HERE ###\n",
    "        rpn_locs = self.loc(middle)\n",
    "        rpn_locs = rpn_locs.permute(0, 2, 3, 1).contiguous().view(n, -1, 4)\n",
    "\n",
    "        # predicted scores for anchor (foreground or background)\n",
    "        ### YOUR CODE HERE\n",
    "        ### ANSWER HERE ###\n",
    "        rpn_scores = self.score(x)\n",
    "        rpn_scores = rpn_scores.permute(0, 2, 3, 1).contiguous()\n",
    "\n",
    "        # scores for foreground\n",
    "        rpn_softmax_scores = F.softmax(rpn_scores.view(n, hh, ww, n_anchor, 2), dim=4)\n",
    "        rpn_fg_scores = rpn_softmax_scores[:, :, :, :, 1].contiguous()\n",
    "        rpn_fg_scores = rpn_fg_scores.view(n, -1)\n",
    "\n",
    "        rpn_scores = rpn_scores.view(n, -1, 2)\n",
    "\n",
    "        # proposal생성 (ProposalCreator)\n",
    "        rois = list()        # proposal의 좌표값이 있는 bounding box array\n",
    "        roi_indices = list() # roi에 해당하는 image 인덱스\n",
    "        for i in range(n):\n",
    "            ### YOUR CODE HERE\n",
    "            ### ANSWER HERE ###\n",
    "            #proposal layer call param: (self, loc, score, anchor, img_size, scale=1.):\n",
    "            roi = self.proposal_layer(rpn_locs[i].cpu().data.numpy(),rpn_fg_scores[i].cpu().data.numpy(),anchor, img_size, scale)\n",
    "            batch_index = i * np.ones((len(roi),), dtype=np.int32)\n",
    "            rois.append(roi)\n",
    "            roi_indices.append(batch_index)\n",
    "        rois = np.concatenate(rois, axis=0)\n",
    "        roi_indices = np.concatenate(roi_indices, axis=0)\n",
    "\n",
    "        return rpn_locs, rpn_scores, rois, roi_indices, anchor\n",
    "\n",
    "\n",
    "def _enumerate_shifted_anchor(anchor_base, feat_stride, height, width):\n",
    "    # anchor_base는 하나의 pixel에 9개 종류의 anchor box를 나타냄\n",
    "    # 이것을 enumerate시켜 전체 이미지의 pixel에 각각 9개의 anchor box를 가지게 함\n",
    "    # 32x32 feature map에서는 32x32x9=9216개의 anchor box가짐\n",
    "\n",
    "    shift_y = np.arange(0, height * feat_stride, feat_stride)\n",
    "    shift_x = np.arange(0, width * feat_stride, feat_stride)\n",
    "    shift_x, shift_y = np.meshgrid(shift_x, shift_y)\n",
    "    shift = np.stack((shift_y.ravel(), shift_x.ravel(),\n",
    "                      shift_y.ravel(), shift_x.ravel()), axis=1)\n",
    "\n",
    "    A = anchor_base.shape[0]\n",
    "    K = shift.shape[0]\n",
    "    anchor = anchor_base.reshape((1, A, 4)) + \\\n",
    "             shift.reshape((1, K, 4)).transpose((1, 0, 2))\n",
    "    anchor = anchor.reshape((K * A, 4)).astype(np.float32)\n",
    "    return anchor # (9216, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ff0bd",
   "metadata": {
    "id": "4e1ff0bd"
   },
   "source": [
    "### Feature extractor(VGG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9911df3f",
   "metadata": {
    "id": "9911df3f"
   },
   "outputs": [],
   "source": [
    "def decom_vgg16():\n",
    "    # the 30th layer of features is relu of conv5_3\n",
    "    model = vgg16(pretrained=True)\n",
    "\n",
    "    features = list(model.features)[:30]\n",
    "    classifier = model.classifier\n",
    "\n",
    "    classifier = list(classifier)\n",
    "    del classifier[6]\n",
    "    if not use_drop:\n",
    "        del classifier[5]\n",
    "        del classifier[2]\n",
    "    classifier = nn.Sequential(*classifier)\n",
    "\n",
    "    # freeze top4 conv\n",
    "    for layer in features[:10]:\n",
    "        for p in layer.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    return nn.Sequential(*features), classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb8f86",
   "metadata": {
    "id": "c1cb8f86"
   },
   "source": [
    "### Faster R-CNN head\n",
    "\n",
    "RoI pool 후에 classifier, regressor 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce8ceb71",
   "metadata": {
    "id": "ce8ceb71"
   },
   "outputs": [],
   "source": [
    "class VGG16RoIHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Faster R-CNN head\n",
    "    RoI pool 후에 classifier, regressior 통과\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_class, roi_size, spatial_scale, classifier):\n",
    "        super(VGG16RoIHead, self).__init__()\n",
    "\n",
    "        self.classifier = classifier\n",
    "        self.cls_loc = nn.Linear(4096, n_class * 4) # bounding box regressor\n",
    "        self.score = nn.Linear(4096, n_class) # Classifier\n",
    "\n",
    "        normal_init(self.cls_loc, 0, 0.001)  # weight initialize\n",
    "        normal_init(self.score, 0, 0.01)     # weight initialize\n",
    "\n",
    "        self.n_class = n_class # 배경 포함한 class 수\n",
    "        self.roi_size = roi_size # RoI-pooling 후 feature map의  높이, 너비\n",
    "        self.spatial_scale = spatial_scale # roi resize scale\n",
    "        self.roi = RoIPool( (self.roi_size, self.roi_size),self.spatial_scale)\n",
    "\n",
    "    def forward(self, x, rois, roi_indices):\n",
    "        # in case roi_indices is  ndarray\n",
    "        roi_indices = totensor(roi_indices).float()\n",
    "        rois = totensor(rois).float()\n",
    "        indices_and_rois = torch.cat([roi_indices[:, None], rois], dim=1)\n",
    "        # NOTE: important: yx->xy\n",
    "        xy_indices_and_rois = indices_and_rois[:, [0, 2, 1, 4, 3]]\n",
    "        indices_and_rois =  xy_indices_and_rois.contiguous()\n",
    "\n",
    "        # 각 이미지 roi pooling\n",
    "        pool = self.roi(x, indices_and_rois)\n",
    "        # flatten\n",
    "        pool = pool.view(pool.size(0), -1)\n",
    "        # fully connected\n",
    "        fc7 = self.classifier(pool)\n",
    "        # regression\n",
    "        roi_cls_locs = self.cls_loc(fc7)\n",
    "        # softmax\n",
    "        roi_scores = self.score(fc7)\n",
    "\n",
    "\n",
    "        return roi_cls_locs, roi_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cec189",
   "metadata": {
    "id": "85cec189"
   },
   "source": [
    "### Faster R-CNN\n",
    "Feature Extraction : image로부터 feature map 생성\\\n",
    "Region Proposal Networks : Region of Interest 생성\\\n",
    "Localization and Classification Head : RoI에 해당하는 feature map을 최종 detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a04aba6",
   "metadata": {
    "id": "0a04aba6"
   },
   "outputs": [],
   "source": [
    "def nograd(f):\n",
    "    def new_f(*args, **kwargs):\n",
    "        with torch.no_grad():\n",
    "            return f(*args, **kwargs)\n",
    "    return new_f\n",
    "\n",
    "class FasterRCNN(nn.Module):\n",
    "    def __init__(self, extractor, rpn, head,\n",
    "                loc_normalize_mean = (0., 0., 0., 0.),\n",
    "                loc_normalize_std = (0.1, 0.1, 0.2, 0.2)):\n",
    "        super(FasterRCNN, self).__init__()\n",
    "        self.extractor = extractor  # extractor : vgg\n",
    "        self.rpn = rpn              # rpn : region proposal network\n",
    "        self.head = head            # head : RoiHead\n",
    "\n",
    "        # mean and std\n",
    "        self.loc_normalize_mean = loc_normalize_mean\n",
    "        self.loc_normalize_std = loc_normalize_std\n",
    "        self.use_preset()\n",
    "\n",
    "    @property\n",
    "    def n_class(self): # 최종 class 개수 (배경 포함)\n",
    "        return self.head.n_class\n",
    "\n",
    "    # predict 시 사용하는 forward\n",
    "    # train 시 FasterRCNNTrainer을 사용하여 FasterRcnn에 있는 extractor, rpn, head를 모듈별로 불러와서 forward\n",
    "    def forward(self, x, scale=1.):\n",
    "        img_size = x.shape[2:]\n",
    "\n",
    "        h = self.extractor(x) # extractor 통과\n",
    "        rpn_locs, rpn_scores, rois, roi_indices, anchor = self.rpn(h, img_size, scale) # rpn 통과\n",
    "        roi_cls_locs, roi_scores = self.head(h, rois, roi_indices) # head 통과\n",
    "        return roi_cls_locs, roi_scores, rois, roi_indices\n",
    "\n",
    "    def use_preset(self): # prediction 과정 쓰이는 threshold 정의\n",
    "        self.nms_thresh = 0.3\n",
    "        self.score_thresh = 0.05\n",
    "\n",
    "    def _suppress(self, raw_cls_bbox, raw_prob):\n",
    "        bbox = list()\n",
    "        label = list()\n",
    "        score = list()\n",
    "\n",
    "        # skip cls_id = 0 because it is the background class\n",
    "        for l in range(1, self.n_class):\n",
    "            cls_bbox_l = raw_cls_bbox.reshape((-1, self.n_class, 4))[:, l, :]\n",
    "            prob_l = raw_prob[:, l]\n",
    "            mask = prob_l > self.score_thresh\n",
    "            cls_bbox_l = cls_bbox_l[mask]\n",
    "            prob_l = prob_l[mask]\n",
    "            keep = nms(cls_bbox_l, prob_l,self.nms_thresh)\n",
    "            bbox.append(cls_bbox_l[keep].cpu().numpy())\n",
    "            # The labels are in [0, self.n_class - 2].\n",
    "            label.append((l - 1) * np.ones((len(keep),)))\n",
    "            score.append(prob_l[keep].cpu().numpy())\n",
    "\n",
    "        bbox = np.concatenate(bbox, axis=0).astype(np.float32)\n",
    "        label = np.concatenate(label, axis=0).astype(np.int32)\n",
    "        score = np.concatenate(score, axis=0).astype(np.float32)\n",
    "        return bbox, label, score\n",
    "\n",
    "    @nograd\n",
    "    def predict(self, imgs,sizes=None):\n",
    "        \"\"\"\n",
    "        이미지에서 객체 검출\n",
    "        Input : images\n",
    "        Output : bboxes, labels, scores\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        prepared_imgs = imgs\n",
    "\n",
    "        bboxes = list()\n",
    "        labels = list()\n",
    "        scores = list()\n",
    "        for img, size in zip(prepared_imgs, sizes):\n",
    "            img = totensor(img[None]).float()\n",
    "            scale = img.shape[3] / size[1]\n",
    "            roi_cls_loc, roi_scores, rois, _ = self(img, scale=scale) # self = FasterRCNN\n",
    "            # We are assuming that batch size is 1.\n",
    "            roi_score = roi_scores.data\n",
    "            roi_cls_loc = roi_cls_loc.data\n",
    "            roi = totensor(rois) / scale\n",
    "\n",
    "            # Convert predictions to bounding boxes in image coordinates.\n",
    "            # Bounding boxes are scaled to the scale of the input images.\n",
    "            mean = torch.Tensor(self.loc_normalize_mean).cuda(). repeat(self.n_class)[None]\n",
    "            std = torch.Tensor(self.loc_normalize_std).cuda(). repeat(self.n_class)[None]\n",
    "\n",
    "            roi_cls_loc = (roi_cls_loc * std + mean)\n",
    "            roi_cls_loc = roi_cls_loc.view(-1, self.n_class, 4)\n",
    "            roi = roi.view(-1, 1, 4).expand_as(roi_cls_loc)\n",
    "            cls_bbox = loc2bbox(tonumpy(roi).reshape((-1, 4)),tonumpy(roi_cls_loc).reshape((-1, 4)))\n",
    "            cls_bbox = totensor(cls_bbox)\n",
    "            cls_bbox = cls_bbox.view(-1, self.n_class * 4)\n",
    "            # clip bounding box\n",
    "            cls_bbox[:, 0::2] = (cls_bbox[:, 0::2]).clamp(min=0, max=size[0])\n",
    "            cls_bbox[:, 1::2] = (cls_bbox[:, 1::2]).clamp(min=0, max=size[1])\n",
    "\n",
    "            prob = (F.softmax(totensor(roi_score), dim=1))\n",
    "\n",
    "            bbox, label, score = self._suppress(cls_bbox, prob)\n",
    "            bboxes.append(bbox)\n",
    "            labels.append(label)\n",
    "            scores.append(score)\n",
    "\n",
    "        self.use_preset()\n",
    "        self.train()\n",
    "        return bboxes, labels, scores\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        '''\n",
    "        Optimizer 선언\n",
    "        '''\n",
    "        lr = learning_rate\n",
    "        params = []\n",
    "        for key, value in dict(self.named_parameters()).items():\n",
    "            if value.requires_grad:\n",
    "                if 'bias' in key:\n",
    "                    params += [{'params': [value], 'lr': lr * 2, 'weight_decay': 0}]\n",
    "                else:\n",
    "                    params += [{'params': [value], 'lr': lr, 'weight_decay': weight_decay}]\n",
    "        self.optimizer = torch.optim.SGD(params, momentum=0.9)\n",
    "        return self.optimizer\n",
    "\n",
    "    def scale_lr(self, decay=0.1):\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] *= decay\n",
    "        return self.optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39849b21",
   "metadata": {
    "id": "39849b21"
   },
   "source": [
    "### Faster R-CNN 생성\n",
    "Extractor(VGG) + RPN + Head 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32726880",
   "metadata": {
    "id": "32726880"
   },
   "outputs": [],
   "source": [
    "class FasterRCNNVGG16(FasterRCNN):\n",
    "\n",
    "    feat_stride = 16  # downsample 16x for output of conv5 in vgg16\n",
    "\n",
    "    def __init__(self, n_fg_class=10, ratios=[0.5, 1, 2], anchor_scales=[8, 16, 32] ): # n_fg_class : 배경포함 하지 않은 class 개수\n",
    "        extractor, classifier = decom_vgg16()\n",
    "\n",
    "        rpn = RegionProposalNetwork(\n",
    "            512, 512,\n",
    "            ratios=ratios,\n",
    "            anchor_scales=anchor_scales,\n",
    "            feat_stride=self.feat_stride,\n",
    "        )\n",
    "\n",
    "        head = VGG16RoIHead(\n",
    "            n_class=n_fg_class + 1,\n",
    "            roi_size=7,\n",
    "            spatial_scale=(1. / self.feat_stride),\n",
    "            classifier=classifier\n",
    "        )\n",
    "        super(FasterRCNNVGG16, self).__init__(\n",
    "            extractor,\n",
    "            rpn,\n",
    "            head,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46202f13",
   "metadata": {
    "id": "46202f13"
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61acb16a",
   "metadata": {
    "id": "61acb16a"
   },
   "source": [
    "#### 0. util 함수 정의\n",
    "bounding box IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9d25d7e",
   "metadata": {
    "id": "c9d25d7e"
   },
   "outputs": [],
   "source": [
    "def bbox_iou(bbox_a, bbox_b):\n",
    "    if bbox_a.shape[1] != 4 or bbox_b.shape[1] != 4:\n",
    "        raise IndexError\n",
    "\n",
    "    #bbox_a 1개와 bbox_b k개를 비교해야하므로 None을 이용해서 차원을 늘려서 연산한다.\n",
    "    # top left\n",
    "    tl = np.maximum(bbox_a[:, None, :2], bbox_b[:, :2])\n",
    "    # bottom right\n",
    "    br = np.minimum(bbox_a[:, None, 2:], bbox_b[:, 2:])\n",
    "\n",
    "    area_i = np.prod(br - tl, axis=2) * (tl < br).all(axis=2)\n",
    "    area_a = np.prod(bbox_a[:, 2:] - bbox_a[:, :2], axis=1)\n",
    "    area_b = np.prod(bbox_b[:, 2:] - bbox_b[:, :2], axis=1)\n",
    "    return area_i / (area_a[:, None] + area_b - area_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ce234",
   "metadata": {
    "id": "ac3ce234"
   },
   "source": [
    "#### 1. Anchor Target Creator\n",
    "Anchor box에 해당하는 ground truth bounding box match\\\n",
    "Region Proposal Network loss 구할 때 ground truth로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69a1e360",
   "metadata": {
    "id": "69a1e360"
   },
   "outputs": [],
   "source": [
    "class AnchorTargetCreator(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_sample=256,\n",
    "                 pos_iou_thresh=0.7, neg_iou_thresh=0.3,\n",
    "                 pos_ratio=0.5):\n",
    "        self.n_sample = n_sample\n",
    "        self.pos_iou_thresh = pos_iou_thresh\n",
    "        self.neg_iou_thresh = neg_iou_thresh\n",
    "        self.pos_ratio = pos_ratio\n",
    "\n",
    "    def __call__(self, bbox, anchor, img_size):\n",
    "\n",
    "        img_H, img_W = img_size\n",
    "\n",
    "        n_anchor = len(anchor) # 9216\n",
    "        inside_index = get_inside_index(anchor, img_H, img_W) # (2272,)\n",
    "        anchor = anchor[inside_index] # (2272, 4)\n",
    "        argmax_ious, label = self._create_label(\n",
    "            inside_index, anchor, bbox)\n",
    "\n",
    "        # compute bounding box regression targets\n",
    "        loc = bbox2loc(anchor, bbox[argmax_ious]) # (2272, 4)\n",
    "\n",
    "        # map up to original set of anchors\n",
    "        label = unmap(label, n_anchor, inside_index, fill=-1) # (9216,)\n",
    "        loc = unmap(loc, n_anchor, inside_index, fill=0) # (9216, 4)\n",
    "\n",
    "        return loc, label\n",
    "\n",
    "    def _create_label(self, inside_index, anchor, bbox):\n",
    "        # label) 1 :positive, 0 : negative, -1 : dont care\n",
    "        label = np.empty((len(inside_index),), dtype=np.int32)\n",
    "        label.fill(-1)\n",
    "\n",
    "        argmax_ious, max_ious, gt_argmax_ious = self._calc_ious(anchor, bbox, inside_index)\n",
    "\n",
    "        label[max_ious < self.neg_iou_thresh] = 0 # 0.3\n",
    "\n",
    "        # 가장 iou가 큰 것은 positive label\n",
    "        label[gt_argmax_ious] = 1\n",
    "\n",
    "        # positive label\n",
    "        label[max_ious >= self.pos_iou_thresh] = 1 # 0.7\n",
    "\n",
    "        # subsample positive labels if we have too many\n",
    "        n_pos = int(self.pos_ratio * self.n_sample)\n",
    "        pos_index = np.where(label == 1)[0]\n",
    "        if len(pos_index) > n_pos:\n",
    "            disable_index = np.random.choice(\n",
    "                pos_index, size=(len(pos_index) - n_pos), replace=False)\n",
    "            label[disable_index] = -1\n",
    "\n",
    "        # subsample negative labels if we have too many\n",
    "        n_neg = self.n_sample - np.sum(label == 1)\n",
    "        neg_index = np.where(label == 0)[0]\n",
    "        if len(neg_index) > n_neg:\n",
    "            disable_index = np.random.choice(\n",
    "                neg_index, size=(len(neg_index) - n_neg), replace=False)\n",
    "            label[disable_index] = -1\n",
    "\n",
    "        return argmax_ious, label\n",
    "\n",
    "    def _calc_ious(self, anchor, bbox, inside_index):\n",
    "        # ious between the anchors and the gt boxes\n",
    "        ious = bbox_iou(anchor, bbox)\n",
    "        argmax_ious = ious.argmax(axis=1)\n",
    "        max_ious = ious[np.arange(len(inside_index)), argmax_ious]\n",
    "        gt_argmax_ious = ious.argmax(axis=0)\n",
    "        gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[1])]\n",
    "        gt_argmax_ious = np.where(ious == gt_max_ious)[0]\n",
    "\n",
    "        return argmax_ious, max_ious, gt_argmax_ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11881f",
   "metadata": {
    "id": "9a11881f"
   },
   "source": [
    "#### 2. positive, negative sampling\n",
    "RPN에서 NMS를 거친 roi들을 ground truth와의 iou를 비교\\\n",
    "positive / negative sampling 수행 (총 128개)\\\n",
    "sample roi와 gt_bbox를 이용해 bbox regression에서 regression해야할 ground truth loc값(t_x, t_y, t_w, t_h)을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6928b27",
   "metadata": {
    "id": "e6928b27"
   },
   "outputs": [],
   "source": [
    "class ProposalTargetCreator:\n",
    "    def __init__(self,\n",
    "                 n_sample=128,\n",
    "                 pos_ratio=0.25, pos_iou_thresh=0.5,\n",
    "                 neg_iou_thresh_hi=0.5, neg_iou_thresh_lo=0.0\n",
    "                 ):\n",
    "        self.n_sample = n_sample\n",
    "        self.pos_ratio = pos_ratio\n",
    "        self.pos_iou_thresh = pos_iou_thresh # positive iou threshold\n",
    "        self.neg_iou_thresh_hi = neg_iou_thresh_hi # negitave iou threshold = (neg_iou_thresh_hi ~ neg_iou_thresh_lo)\n",
    "        self.neg_iou_thresh_lo = neg_iou_thresh_lo\n",
    "\n",
    "    def __call__(self, roi, bbox, label,\n",
    "                 loc_normalize_mean=(0., 0., 0., 0.),\n",
    "                 loc_normalize_std=(0.1, 0.1, 0.2, 0.2)):\n",
    "        n_bbox, _ = bbox.shape\n",
    "\n",
    "        roi = np.concatenate((roi, bbox), axis=0)\n",
    "\n",
    "        pos_roi_per_image = np.round(self.n_sample * self.pos_ratio) # positive image 갯수 = 32\n",
    "        iou = bbox_iou(roi, bbox) # RoI와 bounding box IoU\n",
    "        gt_assignment = iou.argmax(axis=1)\n",
    "        max_iou = iou.max(axis=1)\n",
    "        gt_roi_label = label[gt_assignment] + 1 # class label [0, n_fg_class - 1] -> [1, n_fg_class].\n",
    "\n",
    "        # positive sample 선택 (>= pos_iou_thresh IoU)\n",
    "        pos_index = np.where(max_iou >= self.pos_iou_thresh)[0]\n",
    "        pos_roi_per_this_image = int(min(pos_roi_per_image, pos_index.size))\n",
    "        if pos_index.size > 0:\n",
    "            pos_index = np.random.choice(\n",
    "                pos_index, size=pos_roi_per_this_image, replace=False)\n",
    "\n",
    "        # Negative sample 선택 [neg_iou_thresh_lo, neg_iou_thresh_hi)\n",
    "        neg_index = np.where((max_iou < self.neg_iou_thresh_hi) &\n",
    "                             (max_iou >= self.neg_iou_thresh_lo))[0]\n",
    "        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image\n",
    "        neg_roi_per_this_image = int(min(neg_roi_per_this_image,\n",
    "                                         neg_index.size))\n",
    "        if neg_index.size > 0:\n",
    "            neg_index = np.random.choice(\n",
    "                neg_index, size=neg_roi_per_this_image, replace=False)\n",
    "\n",
    "        # The indices that we're selecting (both positive and negative).\n",
    "        keep_index = np.append(pos_index, neg_index)\n",
    "        gt_roi_label = gt_roi_label[keep_index]\n",
    "        gt_roi_label[pos_roi_per_this_image:] = 0  # negative sample의 label = 0\n",
    "        sample_roi = roi[keep_index] # (128, 4)\n",
    "\n",
    "        # sample roi와 gt_bbox를 이용해 bbox regression에서 regression해야할 ground truth loc값(t_x, t_y, t_w, t_h) 계산\n",
    "        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]]) # (128, 4)\n",
    "        gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)) / np.array(loc_normalize_std, np.float32))\n",
    "\n",
    "        return sample_roi, gt_roi_loc, gt_roi_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2da581",
   "metadata": {
    "id": "ec2da581"
   },
   "source": [
    "#### 3. Trainer 정의\n",
    "training, loss 계산, checkpoint 저장 및 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40ccd0b",
   "metadata": {
    "id": "d40ccd0b"
   },
   "outputs": [],
   "source": [
    "LossTuple = namedtuple('LossTuple', ['rpn_loc_loss', 'rpn_cls_loss',\n",
    "                                     'roi_loc_loss', 'roi_cls_loss',\n",
    "                                     'total_loss'])\n",
    "class FasterRCNNTrainer(nn.Module):\n",
    "\n",
    "    def __init__(self, faster_rcnn):\n",
    "        super(FasterRCNNTrainer, self).__init__()\n",
    "\n",
    "        self.faster_rcnn = faster_rcnn\n",
    "        self.rpn_sigma = rpn_sigma\n",
    "        self.roi_sigma = roi_sigma\n",
    "\n",
    "        # target creator create gt_bbox gt_label etc as training targets.\n",
    "        self.anchor_target_creator = AnchorTargetCreator()\n",
    "        self.proposal_target_creator = ProposalTargetCreator()\n",
    "\n",
    "        self.loc_normalize_mean = faster_rcnn.loc_normalize_mean\n",
    "        self.loc_normalize_std = faster_rcnn.loc_normalize_std\n",
    "\n",
    "        self.optimizer = self.faster_rcnn.get_optimizer()\n",
    "\n",
    "        # training 상태 보여주는 지표\n",
    "        self.rpn_cm = ConfusionMeter(2) # confusion matrix for classification\n",
    "        self.roi_cm = ConfusionMeter(11)  # confusion matrix for classification\n",
    "        self.meters = {k: AverageValueMeter() for k in LossTuple._fields}  # average loss\n",
    "\n",
    "    def forward(self, imgs, bboxes, labels, scale):\n",
    "        n = bboxes.shape[0]\n",
    "\n",
    "        if n != 1:\n",
    "            raise ValueError('Currently only batch size 1 is supported.')\n",
    "\n",
    "        _, _, H, W = imgs.shape\n",
    "        img_size = (H, W)\n",
    "\n",
    "        # VGG (features extractor)\n",
    "        features = self.faster_rcnn.extractor(imgs)\n",
    "\n",
    "        # RPN (region proposal)\n",
    "        rpn_locs, rpn_scores, rois, roi_indices, anchor = self.faster_rcnn.rpn(features, img_size, scale)\n",
    "\n",
    "        # Since batch size is one, convert variables to singular form\n",
    "        bbox = bboxes[0]\n",
    "        label = labels[0]\n",
    "        rpn_score = rpn_scores[0]\n",
    "        rpn_loc = rpn_locs[0]\n",
    "        roi = rois\n",
    "\n",
    "        \"\"\"\n",
    "        sample roi =  rpn에서 nms 거친 2000개의 roi들 중 positive/negative 비율 고려해 최종 sampling한 roi\n",
    "        \"\"\"\n",
    "        sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(\n",
    "            roi,\n",
    "            tonumpy(bbox),\n",
    "            tonumpy(label),\n",
    "            self.loc_normalize_mean,\n",
    "            self.loc_normalize_std)\n",
    "\n",
    "        # NOTE it's all zero because now it only support for batch=1 now\n",
    "        # Faster R-CNN head (prediction head)\n",
    "        sample_roi_index = torch.zeros(len(sample_roi))\n",
    "        roi_cls_loc, roi_score = self.faster_rcnn.head(features,sample_roi,sample_roi_index)\n",
    "\n",
    "        # ------------------ RPN losses -------------------#\n",
    "        gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(tonumpy(bbox),anchor,img_size)\n",
    "        gt_rpn_label = totensor(gt_rpn_label).long()\n",
    "        gt_rpn_loc = totensor(gt_rpn_loc)\n",
    "\n",
    "        # rpn bounding box regression loss\n",
    "        rpn_loc_loss = _fast_rcnn_loc_loss(rpn_loc,gt_rpn_loc,gt_rpn_label.data,self.rpn_sigma)\n",
    "        # rpn classification loss\n",
    "        rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-1)\n",
    "\n",
    "        _gt_rpn_label = gt_rpn_label[gt_rpn_label > -1]\n",
    "        _rpn_score = tonumpy(rpn_score)[tonumpy(gt_rpn_label) > -1]\n",
    "        self.rpn_cm.add(totensor(_rpn_score, False), _gt_rpn_label.data.long())\n",
    "\n",
    "        # ------------------ ROI losses (fast rcnn loss) -------------------#\n",
    "        n_sample = roi_cls_loc.shape[0]\n",
    "        roi_cls_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
    "        roi_loc = roi_cls_loc[torch.arange(0, n_sample).long().cuda(), \\\n",
    "                              totensor(gt_roi_label).long()]\n",
    "        gt_roi_label = totensor(gt_roi_label).long()\n",
    "        gt_roi_loc = totensor(gt_roi_loc)\n",
    "\n",
    "        # faster rcnn bounding box regression loss\n",
    "        roi_loc_loss = _fast_rcnn_loc_loss(\n",
    "            roi_loc.contiguous(),\n",
    "            gt_roi_loc,\n",
    "            gt_roi_label.data,\n",
    "            self.roi_sigma)\n",
    "\n",
    "        # faster rcnn classification loss\n",
    "        roi_cls_loss = nn.CrossEntropyLoss()(roi_score, gt_roi_label.cuda())\n",
    "\n",
    "        self.roi_cm.add(totensor(roi_score, False), gt_roi_label.data.long())\n",
    "\n",
    "        losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]\n",
    "        losses = losses + [sum(losses)] # total_loss == sum(losses)\n",
    "\n",
    "        return LossTuple(*losses)\n",
    "\n",
    "    # training\n",
    "    def train_step(self, imgs, bboxes, labels, scale):\n",
    "        self.optimizer.zero_grad()\n",
    "        losses = self.forward(imgs, bboxes, labels, scale)\n",
    "        losses.total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.update_meters(losses)\n",
    "        return losses\n",
    "\n",
    "    # checkpoint 만들기\n",
    "    def save(self, save_optimizer=False, save_path=None):\n",
    "        save_dict = dict()\n",
    "\n",
    "        save_dict['model'] = self.faster_rcnn.state_dict()\n",
    "\n",
    "        if save_optimizer:\n",
    "            save_dict['optimizer'] = self.optimizer.state_dict()\n",
    "\n",
    "        if save_path is None:\n",
    "            save_path = './checkpoints/faster_rcnn_scratch_checkpoints.pth'\n",
    "\n",
    "        save_dir = os.path.dirname(save_path)\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        torch.save(save_dict, save_path)\n",
    "        return save_path\n",
    "\n",
    "    # checkpoint load\n",
    "    def load(self, path, load_optimizer=True, parse_opt=False, ):\n",
    "        state_dict = torch.load(path)\n",
    "        if 'model' in state_dict:\n",
    "            self.faster_rcnn.load_state_dict(state_dict['model'])\n",
    "        else:  # legacy way, for backward compatibility\n",
    "            self.faster_rcnn.load_state_dict(state_dict)\n",
    "            return self\n",
    "        if 'optimizer' in state_dict and load_optimizer:\n",
    "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "        return self\n",
    "\n",
    "    def update_meters(self, losses):\n",
    "        loss_d = {k: scalar(v) for k, v in losses._asdict().items()}\n",
    "        for key, meter in self.meters.items():\n",
    "            meter.add(loss_d[key])\n",
    "\n",
    "    def reset_meters(self):\n",
    "        for key, meter in self.meters.items():\n",
    "            meter.reset()\n",
    "        self.roi_cm.reset()\n",
    "        self.rpn_cm.reset()\n",
    "\n",
    "    def get_meter_data(self):\n",
    "        return {k: v.value()[0] for k, v in self.meters.items()}\n",
    "\n",
    "\n",
    "def _smooth_l1_loss(x, t, in_weight, sigma):\n",
    "    sigma2 = sigma ** 2\n",
    "    diff = in_weight * (x - t)\n",
    "    abs_diff = diff.abs()\n",
    "    flag = (abs_diff.data < (1. / sigma2)).float()\n",
    "    y = (flag * (sigma2 / 2.) * (diff ** 2) +\n",
    "         (1 - flag) * (abs_diff - 0.5 / sigma2))\n",
    "    return y.sum()\n",
    "\n",
    "\n",
    "def _fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n",
    "    # Localization loss 구할 때는 positive example에 대해서만 계산\n",
    "    in_weight = torch.zeros(gt_loc.shape).cuda()\n",
    "    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n",
    "    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma)\n",
    "    loc_loss /= ((gt_label >= 0).sum().float())\n",
    "    return loc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b03eee6",
   "metadata": {
    "id": "2b03eee6"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c9224c3",
   "metadata": {
    "id": "9c9224c3"
   },
   "outputs": [],
   "source": [
    "lossgraph = []\n",
    "def train():\n",
    "    # Train dataset 불러오기\n",
    "#     dataset = TrainDataset()\n",
    "    annotation = os.path.join(data_dir,'train.json')\n",
    "    dataset = TrainCustom(annotation, data_dir, transforms=True)\n",
    "    print('load data')\n",
    "    dataloader = data_.DataLoader(dataset,\n",
    "                                  batch_size=1,     # only batch_size=1 support\n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=False,\n",
    "                                  num_workers=0)\n",
    "\n",
    "    # faster rcnn 불러오기\n",
    "    faster_rcnn = FasterRCNNVGG16().cuda()\n",
    "    print('model construct completed')\n",
    "\n",
    "    # faster rcnn trainer 불러오기\n",
    "    trainer = FasterRCNNTrainer(faster_rcnn).cuda()\n",
    "\n",
    "    # checkpoint load\n",
    "    if train_load_path:\n",
    "        trainer.load(train_load_path)\n",
    "        print('load pretrained model from %s' % train_load_path)\n",
    "\n",
    "    lr_ = learning_rate\n",
    "    best_loss = 1000\n",
    "    for epoch in range(epochs):\n",
    "        trainer.reset_meters()\n",
    "        for ii, (img, bbox_, label_, scale) in enumerate(tqdm(dataloader)):\n",
    "\n",
    "            img, bbox, label = img.cuda().float(), bbox_.cuda(), label_.cuda()\n",
    "            trainer.train_step(img, bbox, label, float(scale))\n",
    "\n",
    "        losses = trainer.get_meter_data()\n",
    "        lossgraph.append(losses)\n",
    "        print(f\"Epoch #{epoch+1} loss: {losses}\")\n",
    "        if losses['total_loss'] < best_loss :\n",
    "            trainer.save()\n",
    "\n",
    "        if epoch == 9:\n",
    "            trainer.faster_rcnn.scale_lr(lr_decay)\n",
    "            lr_ = lr_ * lr_decay\n",
    "\n",
    "        if epoch == 13:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d704420",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "id": "1d704420",
    "outputId": "6e5ad565-dd34-4684-b7a4-dc4611c325ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.05s)\n",
      "creating index...\n",
      "index created!\n",
      "load data\n",
      "model construct completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:53<00:00,  7.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1 loss: {'rpn_loc_loss': 0.16247458991134683, 'rpn_cls_loss': 0.36815554334623934, 'roi_loc_loss': 0.2752804897842394, 'roi_cls_loss': 0.5544557666366744, 'total_loss': 1.3603663899335574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2 loss: {'rpn_loc_loss': 0.15590806831624868, 'rpn_cls_loss': 0.3341008240249089, 'roi_loc_loss': 0.25127447628147775, 'roi_cls_loss': 0.5233017546495718, 'total_loss': 1.2645851245656177}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3 loss: {'rpn_loc_loss': 0.15376180668603998, 'rpn_cls_loss': 0.32417610797042395, 'roi_loc_loss': 0.23767173403690148, 'roi_cls_loss': 0.5045567478365867, 'total_loss': 1.220166395653135}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:36<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4 loss: {'rpn_loc_loss': 0.152597826600098, 'rpn_cls_loss': 0.31642657740546243, 'roi_loc_loss': 0.23130492184952728, 'roi_cls_loss': 0.503448856542677, 'total_loss': 1.2037781816866209}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5 loss: {'rpn_loc_loss': 0.1510653838325224, 'rpn_cls_loss': 0.31182831109577824, 'roi_loc_loss': 0.23041592295847427, 'roi_cls_loss': 0.49805219358696384, 'total_loss': 1.1913618118825051}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:36<00:00,  7.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6 loss: {'rpn_loc_loss': 0.15019240725435357, 'rpn_cls_loss': 0.3143058441109759, 'roi_loc_loss': 0.22434005648504846, 'roi_cls_loss': 0.49209201911217587, 'total_loss': 1.1809303275027832}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:35<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7 loss: {'rpn_loc_loss': 0.14899829586014532, 'rpn_cls_loss': 0.3103457038358887, 'roi_loc_loss': 0.22034265399060715, 'roi_cls_loss': 0.4819933487788617, 'total_loss': 1.161680004106862}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:32<00:00,  7.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8 loss: {'rpn_loc_loss': 0.14901322650952428, 'rpn_cls_loss': 0.30345444484916567, 'roi_loc_loss': 0.21959957169030805, 'roi_cls_loss': 0.47882545150827205, 'total_loss': 1.1508926959701082}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:30<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9 loss: {'rpn_loc_loss': 0.14764403046529304, 'rpn_cls_loss': 0.29966312420548596, 'roi_loc_loss': 0.2164406637875681, 'roi_cls_loss': 0.47272447376494153, 'total_loss': 1.1364722923161492}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #10 loss: {'rpn_loc_loss': 0.1474729868671472, 'rpn_cls_loss': 0.30149441975325847, 'roi_loc_loss': 0.21399761361869166, 'roi_cls_loss': 0.47158412407712147, 'total_loss': 1.134549144611981}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #11 loss: {'rpn_loc_loss': 0.14525762375013324, 'rpn_cls_loss': 0.2894475146444921, 'roi_loc_loss': 0.20463079856766292, 'roi_cls_loss': 0.4359906234881647, 'total_loss': 1.075326560159369}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:36<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #12 loss: {'rpn_loc_loss': 0.14388995557033338, 'rpn_cls_loss': 0.2863804645677663, 'roi_loc_loss': 0.20436170664888176, 'roi_cls_loss': 0.4288722264534466, 'total_loss': 1.0635043526407468}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:35<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #13 loss: {'rpn_loc_loss': 0.14369618626631622, 'rpn_cls_loss': 0.2866727950133626, 'roi_loc_loss': 0.2060045152819113, 'roi_cls_loss': 0.4307829268288512, 'total_loss': 1.067156423119015}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4883/4883 [10:34<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #14 loss: {'rpn_loc_loss': 0.1444103681771023, 'rpn_cls_loss': 0.2882422395812486, 'roi_loc_loss': 0.2041955727331011, 'roi_cls_loss': 0.4266890147185949, 'total_loss': 1.0635371948061219}\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae5741be-f3e6-4126-890a-4c5335d20571",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(1,len(lossgraph)+1))\n",
    "rpn_loc_losses = [item['rpn_loc_loss'] for item in lossgraph]\n",
    "rpn_cls_losses = [item['rpn_cls_loss'] for item in lossgraph]\n",
    "roi_loc_losses = [item['roi_loc_loss'] for item in lossgraph]\n",
    "roi_cls_losses = [item['roi_cls_loss'] for item in lossgraph]\n",
    "total_losses = [item['total_loss'] for item in lossgraph]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9af25db-8cb9-4fd0-8418-8f27cb53d6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, rpn_loc_losses, label='rpn_loc_loss')\n",
    "plt.plot(x, rpn_cls_losses, label='rpn_cls_loss')\n",
    "plt.plot(x, roi_loc_losses, label='roi_loc_loss')\n",
    "plt.plot(x, roi_cls_losses, label='roi_cls_loss')\n",
    "plt.title('loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "944906c4-3781-481c-be9d-c637b052a285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,total_losses)\n",
    "plt.title('total_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0771b1d",
   "metadata": {
    "id": "b0771b1d"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43a67b27",
   "metadata": {
    "id": "43a67b27"
   },
   "outputs": [],
   "source": [
    "def eval(dataloader, faster_rcnn):\n",
    "    outputs = []\n",
    "    for ii, (imgs, sizes) in enumerate(tqdm(dataloader)):\n",
    "        sizes = [sizes[0][0].item(), sizes[1][0].item()]\n",
    "        pred_bboxes_, pred_labels_, pred_scores_ = faster_rcnn.predict(imgs, [sizes])\n",
    "        for out in range(len(pred_bboxes_)):\n",
    "            outputs.append({'boxes':pred_bboxes_[out], 'scores': pred_scores_[out], 'labels': pred_labels_[out]})\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c77514fc",
   "metadata": {
    "id": "c77514fc"
   },
   "outputs": [],
   "source": [
    "def inference():\n",
    "\n",
    "    # Test dataset 불러오기\n",
    "#     testset = TestDataset()\n",
    "    annotation = os.path.join(data_dir,'test.json')\n",
    "    testset = TestCustom(annotation, data_dir)\n",
    "    test_dataloader = data_.DataLoader(testset,\n",
    "                                       batch_size=1, # only batch_size=1 support\n",
    "                                       num_workers=0,\n",
    "                                       shuffle=False,\n",
    "                                       pin_memory=False\n",
    "                                       )\n",
    "    # faster rcnn 불러오기\n",
    "    faster_rcnn = FasterRCNNVGG16().cuda()\n",
    "    state_dict = torch.load(inf_load_path)\n",
    "    if 'model' in state_dict:\n",
    "        faster_rcnn.load_state_dict(state_dict['model'])\n",
    "    print('load pretrained model from %s' % inf_load_path)\n",
    "\n",
    "    # evaluation\n",
    "    outputs = eval(test_dataloader, faster_rcnn)\n",
    "    score_threshold = 0.05\n",
    "    prediction_strings = []\n",
    "    file_names = []\n",
    "\n",
    "    # submission file 작성\n",
    "    coco = COCO(os.path.join(data_dir, 'test.json'))\n",
    "    for i, output in enumerate(outputs):\n",
    "        prediction_string = ''\n",
    "        image_info = coco.loadImgs(coco.getImgIds(imgIds=i))[0]\n",
    "        for box, score, label in zip(output['boxes'], output['scores'], output['labels']):\n",
    "            if score > score_threshold:\n",
    "                prediction_string += str(label) + ' ' + str(score) + ' ' + str(box[1]) + ' ' + str(\n",
    "                    box[0]) + ' ' + str(box[3]) + ' ' + str(box[2]) + ' '\n",
    "        prediction_strings.append(prediction_string)\n",
    "        file_names.append(image_info['file_name'])\n",
    "    submission = pd.DataFrame()\n",
    "    submission['PredictionString'] = prediction_strings\n",
    "    submission['image_id'] = file_names\n",
    "    submission.to_csv(\"./faster_rcnn_scratch_submission.csv\", index=False)\n",
    "\n",
    "    print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06b16e50",
   "metadata": {
    "id": "06b16e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "load pretrained model from ./checkpoints/faster_rcnn_scratch_checkpoints.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4871/4871 [05:54<00:00, 13.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "                                    PredictionString       image_id\n",
      "0  0 0.3039394 226.94513 678.1798 298.925 748.526...  test/0000.jpg\n",
      "1  0 0.10770073 144.20366 0.0 504.00995 280.3994 ...  test/0001.jpg\n",
      "2  0 0.7105983 304.70834 52.54503 338.92648 178.2...  test/0002.jpg\n",
      "3  0 0.17072758 0.0 53.446747 309.8661 697.2634 0...  test/0003.jpg\n",
      "4  0 0.41029322 211.4574 314.56238 728.33984 793....  test/0004.jpg\n"
     ]
    }
   ],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8b59f",
   "metadata": {
    "id": "c4f8b59f"
   },
   "source": [
    "# Reference\n",
    "https://github.com/chenyuntc/simple-faster-rcnn-pytorch \\\n",
    "https://github.com/shkim960520/faster-rcnn-for-studying"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
